{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# AI-based denoising\n\nDenoising based on the deep learning model proposed in [1]_.\n\nApplied to the original data from [1]_ and a slice from [2]_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import LinearSegmentedColormap\nfrom statannotations.Annotator import Annotator\n\nimport ramanspy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting up constants and plotting parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SEED = 19\n\nmatplotlib.rc_file_defaults()\nplt.rc('font', size=16)          # controls default text sizes\nplt.rc('axes', titlesize=24)     # fontsize of the axes title\nplt.rc('xtick', labelsize=16)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=16)    # fontsize of the tick labels\nplt.rc('legend', fontsize=16)    # legend fontsize\nplt.rc('figure', titlesize=24)  # fontsize of the figure title\n\nMETRICS = ['MSE', 'SAD', 'SID']\ncolors = list(plt.cm.get_cmap()(np.linspace(0, 1, 4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create denoisers\nWe will start by defining the denoisers we will use.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AI-based denoiser\nFirst, we will define and load the AI-based denoiser. This is based on the deep learning model proposed in [1]_. The model\nis pretrained on pairs of low-signal-to-noise (SNR) and high-SNR spectra. The trained model has been deposited by the authors\non [GitHub](https://github.com/conor-horgan/DeepeR/blob/master/Raman%20Spectral%20Denoising/model.py).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"MIT License\n\nCopyright (c) 2020 conor-horgan\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\"\"\"\n\nimport torch\nfrom torch import nn\n\n\nclass BasicConv(nn.Module):\n    def __init__(self, channels_in, channels_out, batch_norm):\n        super(BasicConv, self).__init__()\n        basic_conv = [nn.Conv1d(channels_in, channels_out, kernel_size=3, stride=1, padding=1, bias=True)]\n        basic_conv.append(nn.PReLU())\n        if batch_norm:\n            basic_conv.append(nn.BatchNorm1d(channels_out))\n\n        self.body = nn.Sequential(*basic_conv)\n\n    def forward(self, x):\n        return self.body(x)\n\n\nclass ResUNetConv(nn.Module):\n    def __init__(self, num_convs, channels, batch_norm):\n        super(ResUNetConv, self).__init__()\n        unet_conv = []\n        for _ in range(num_convs):\n            unet_conv.append(nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=1, bias=True))\n            unet_conv.append(nn.PReLU())\n            if batch_norm:\n                unet_conv.append(nn.BatchNorm1d(channels))\n\n        self.body = nn.Sequential(*unet_conv)\n\n    def forward(self, x):\n        res = self.body(x)\n        res += x\n        return res\n\n\nclass UNetLinear(nn.Module):\n    def __init__(self, repeats, channels_in, channels_out):\n        super().__init__()\n        modules = []\n        for i in range(repeats):\n            modules.append(nn.Linear(channels_in, channels_out))\n            modules.append(nn.PReLU())\n\n        self.body = nn.Sequential(*modules)\n\n    def forward(self, x):\n        x = self.body(x)\n        return x\n\n\nclass ResUNet(nn.Module):\n    def __init__(self, num_convs, batch_norm):\n        super(ResUNet, self).__init__()\n        res_conv1 = [BasicConv(1, 64, batch_norm)]\n        res_conv1.append(ResUNetConv(num_convs, 64, batch_norm))\n        self.conv1 = nn.Sequential(*res_conv1)\n        self.pool1 = nn.MaxPool1d(2)\n\n        res_conv2 = [BasicConv(64, 128, batch_norm)]\n        res_conv2.append(ResUNetConv(num_convs, 128, batch_norm))\n        self.conv2 = nn.Sequential(*res_conv2)\n        self.pool2 = nn.MaxPool1d(2)\n\n        res_conv3 = [BasicConv(128, 256, batch_norm)]\n        res_conv3.append(ResUNetConv(num_convs, 256, batch_norm))\n        res_conv3.append(BasicConv(256, 128, batch_norm))\n        self.conv3 = nn.Sequential(*res_conv3)\n        self.up3 = nn.Upsample(scale_factor=2)\n\n        res_conv4 = [BasicConv(256, 128, batch_norm)]\n        res_conv4.append(ResUNetConv(num_convs, 128, batch_norm))\n        res_conv4.append(BasicConv(128, 64, batch_norm))\n        self.conv4 = nn.Sequential(*res_conv4)\n        self.up4 = nn.Upsample(scale_factor=2)\n\n        res_conv5 = [BasicConv(128, 64, batch_norm)]\n        res_conv5.append(ResUNetConv(num_convs, 64, batch_norm))\n        self.conv5 = nn.Sequential(*res_conv5)\n        res_conv6 = [BasicConv(64, 1, batch_norm)]\n        self.conv6 = nn.Sequential(*res_conv6)\n\n        self.linear7 = UNetLinear(3, 500, 500)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x1 = self.pool1(x)\n\n        x2 = self.conv2(x1)\n        x3 = self.pool1(x2)\n\n        x3 = self.conv3(x3)\n        x3 = self.up3(x3)\n\n        x4 = torch.cat((x2, x3), dim=1)\n        x4 = self.conv4(x4)\n        x5 = self.up4(x4)\n\n        x6 = torch.cat((x, x5), dim=1)\n        x6 = self.conv5(x6)\n        x7 = self.conv6(x6)\n\n        out = self.linear7(x7)\n\n        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the pretrained model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net = ResUNet(3, False).float()\nnet.load_state_dict(torch.load(r\"ResUNet.pt\", map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use it, we define a preprocessing step based on the pretrained model by wrapping it as a PreprocessingStep instance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def nn_preprocesing(spectral_data, wavenumber_axis):\n    flat_spectral_data = spectral_data.reshape(-1, spectral_data.shape[-1])\n\n    output = net(torch.Tensor(flat_spectral_data).unsqueeze(1)).cpu().detach().numpy()\n    output = np.squeeze(output)\n\n    output = output.reshape(spectral_data.shape)\n\n    return output, wavenumber_axis\n\n\nnn_denoiser = ramanspy.preprocessing.PreprocessingStep(nn_preprocesing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Baseline denoisers\n\nNext, we define a set of baseline correction denoisers based on Savitzky-Golay filtering [3]_ with different parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "baseliners = {\n    'SG (2, 5)': ramanspy.preprocessing.denoise.SavGol(window_length=5, polyorder=2),\n    'SG (2, 7)': ramanspy.preprocessing.denoise.SavGol(window_length=7, polyorder=2),\n    'SG (2, 9)': ramanspy.preprocessing.denoise.SavGol(window_length=9, polyorder=2),\n    'SG (3, 5)': ramanspy.preprocessing.denoise.SavGol(window_length=5, polyorder=3),\n    'SG (3, 7)': ramanspy.preprocessing.denoise.SavGol(window_length=7, polyorder=3),\n    'SG (3, 9)': ramanspy.preprocessing.denoise.SavGol(window_length=9, polyorder=3),\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utility methods\nWe will also define a set of utility methods to help us extract and compare the results of the different denoisers.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a MinMax scalar.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "minmax = ramanspy.preprocessing.normalise.MinMax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a method that extracts the results achieved by a denoiser with respect to the defined metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_results(spectrum_to_denoise, target, denoiser):\n    # Normalise input and output to 0-1\n    spectrum_to_denoise = minmax.apply(spectrum_to_denoise)\n    target = minmax.apply(target)\n\n    output = denoiser.apply(spectrum_to_denoise)\n\n    metrics_result = {metric: getattr(ramanspy.metrics, metric)(output, target) for metric in METRICS}\n\n    return output, metrics_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a small utility method to plot the results of comparing the baseline and the AI-based denoiser across the defined metrics.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def show_results(nn_results_df, baseline_results_dfs):\n    for metric in METRICS:\n        plt.figure(figsize=(4, 6), tight_layout=True)\n\n        bar_kwargs = {'linewidth': 2, 'zorder': 5}\n        err_kwargs = {'zorder': 0, 'fmt': 'none', 'linewidth': 2, 'ecolor': 'k', 'capsize': 5}\n\n        combined_df = pd.concat([nn_results_df[metric], *[df[metric] for df in baseline_results_dfs.values()]], axis=1,\n                                ignore_index=True)\n        combined_df.columns = ['NN'] + list(baseline_results_dfs.keys())\n\n        # Plot\n        means = combined_df.mean()\n        stds = combined_df.std()\n        labels = combined_df.columns\n\n        sg_cmap = LinearSegmentedColormap.from_list('', [colors[1], [1, 1, 1, 1]])\n        colors_to_use = list(sg_cmap(np.linspace(0, 1, len(baseliners.keys()) + 2)))[:-2]\n\n        ax = plt.gca()\n        ax.bar(labels, means, color=[colors[3]] + colors_to_use[::-1], **bar_kwargs)\n        ax.errorbar(labels, means, yerr=[[0] * len(stds), stds], **err_kwargs)\n\n        # Significance tests\n        combined_df_ = combined_df.melt(var_name='Denoiser', value_name=metric)\n        box_pairs = [('NN', base) for base in baseliners.keys()]\n        annotator = Annotator(ax, box_pairs, data=combined_df_, x=\"Denoiser\", y=metric)\n        annotator.configure(test='Wilcoxon', text_format='star', loc='inside', comparisons_correction='fdr_bh')\n        annotator.apply_and_annotate()\n\n        ax.set_title(metric)\n        plt.xticks(rotation=45, ha='right')\n        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original data (MDA_MB_231 cells)\nWe will use the MDA_MB_231 cells dataset from the original paper [1]_ to investigate the performance of the proposed\nAI-based denoiser.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data\nWe will use the test set of the MDA_MB_231 cells dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dir_ = r'../../../data/horgan_data'\nMDA_MB_231_X_test, MDA_MB_231_Y_test = ramanspy.datasets.MDA_MB_231_cells(dataset='test', folder=dir_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example spectrum\nDenoising results on an example spectrum.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n\nselected_index = np.random.randint(0, MDA_MB_231_X_test.shape[0])\nselected_input, selected_target = MDA_MB_231_X_test[selected_index], MDA_MB_231_Y_test[selected_index]\n\nnn_results = get_results(selected_input, selected_target, nn_denoiser)[0]\nbaseline_results = get_results(selected_input, selected_target, baseliners['SG (3, 9)'])[0]\n\nresults = minmax.apply([selected_input, baseline_results, selected_target, nn_results])\nlabels = ['Low SNR Input', 'Savitzky-Golay (3, 9)', 'High SNR Target', 'Neural network']\n\nplt.figure(figsize=(10, 4), tight_layout=True)\nax = ramanspy.plot.spectra(results, plot_type='single', ylabel='Normalised intensity', title='Original dataset', color=colors)\nax.legend(labels)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results on entire dataset\nDenoising results on the entire testing dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "original_baseline_results_dfs = {k: pd.DataFrame(columns=METRICS) for k in baseliners.keys()}\noriginal_nn_results_df = pd.DataFrame(columns=METRICS)\nfor input, target in zip(MDA_MB_231_X_test, MDA_MB_231_Y_test):\n    original_nn_results_df = pd.concat([original_nn_results_df, pd.DataFrame([get_results(input, target, nn_denoiser)[1]])], ignore_index=True)\n\n    for name, denoiser in baseliners.items():\n        original_baseline_results_dfs[name] = pd.concat([original_baseline_results_dfs[name], pd.DataFrame([get_results(input, target, denoiser)[1]])], ignore_index=True)\n\nshow_results(original_nn_results_df, original_baseline_results_dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer data (THP-1 cells)\nTo showcase transferability and study generalisation, we will repeat the same experiment on a different unseen dataset.\nWe will use the THP-1 cells dataset from [2]_.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data\nHere, we will load the fifth image layer of the first THP-1 cell sample. Note that we have already preprocessed the data\nfollowing the same preprocessing steps as in [1]_ for consistency. This included spectral cropping to the 500-1800 cm :sup:`-1` range,\nfollowed by baseline correction using the 'shape' method in the WITec Project FIVE software with $\\alpha = 500$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "thp_slice = ramanspy.load.witec(r\"3D THP1 map 001 L5 (B+R) (Sub BG).mat\")\nthp_slice = thp_slice.flat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple method to add normal noise to a spectrum that we will use to generate noisy spectra for each spectrum in the\nTHP-1 cells data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def add_normal_noise(spectrum, std=0.15):\n    spectrum = ramanspy.preprocessing.normalise.MinMax().apply(spectrum)\n\n    # add noise\n    noise = np.random.normal(0, std, len(spectrum.spectral_data))\n    noisy_spectrum = ramanspy.Spectrum(spectrum.spectral_data + noise, spectrum.spectral_axis)\n\n    return noisy_spectrum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example spectrum\nDenoising results on an example spectrum.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n\nselected_index = np.random.randint(0, thp_slice.shape[0])\nselected_target = thp_slice[selected_index]\nselected_input = add_normal_noise(selected_target)\n\nnn_results = get_results(selected_input, selected_target, nn_denoiser)[0]\nbaseline_results = get_results(selected_input, selected_target, baseliners['SG (3, 9)'])[0]\n\nresults = minmax.apply([selected_input, baseline_results, selected_target, nn_results])\nlabels = ['Input (data with noise)', 'Savitzky-Golay (3, 9)', 'Target (authentic data)', 'Neural network']\n\nplt.figure(figsize=(10, 4), tight_layout=True)\nax = ramanspy.plot.spectra(results, plot_type='single', ylabel='Normalised intensity', title='Transfer dataset', color=colors)\nax.legend(labels)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results on transfer data\nDenoising results on the entire transfer dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transfer_baseline_results_dfs = {k: pd.DataFrame(columns=METRICS) for k in baseliners.keys()}\ntransfer_nn_results_df = pd.DataFrame(columns=METRICS)\nfor spectrum in thp_slice:\n    spectrum_with_noise = add_normal_noise(spectrum)\n    transfer_nn_results_df = pd.concat([transfer_nn_results_df, pd.DataFrame([get_results(spectrum_with_noise, spectrum, nn_denoiser)[1]])], ignore_index=True)\n\n    for name, denoiser in baseliners.items():\n        transfer_baseline_results_dfs[name] = pd.concat([transfer_baseline_results_dfs[name], pd.DataFrame([get_results(spectrum_with_noise, spectrum, denoiser)[1]])], ignore_index=True)\n\nshow_results(transfer_nn_results_df, transfer_baseline_results_dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n.. [1] Horgan, C.C., Jensen, M., Nagelkerke, A., St-Pierre, J.P., Vercauteren, T., Stevens, M.M. and Bergholt, M.S., 2021. High-Throughput Molecular Imaging via Deep-Learning-Enabled Raman Spectroscopy. Analytical Chemistry, 93(48), pp.15850-15860.\n\n.. [2] Kallepitis, C., Bergholt, M., Mazo, M. et al. Quantitative volumetric Raman imaging of three dimensional cell cultures. Nat Commun 8, 14843 (2017).\n\n.. [3] Savitzky A, Golay MJ. Smoothing and differentiation of data by simplified least squares procedures. Analytical chemistry. 1964 Jul 1;36(8):1627-39.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}