{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Integrative analysis: Neural Network (NN) classification\n\nIn this example, we will showcase `RamanSPy's` integrability by integrating a Neural Network (NN)\nmodel for the identification of different bacteria species.\n\nTo build the model, we will use the [tensorflow](https://tensorflow.org/) Python framework, but similar integrative\nanalyses are possible with the rest of the Python machine learning and deep learning ecosystem.\n\nThe data we will use is the `Bacteria data`, which is integrated into `RamanSPy`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.utils import shuffle\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport ramanspy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will use `RamanSPy` to load the validation and testing bacteria datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dir_ = r\"../../../../data/bacteria_data\"\n\nX_train, y_train = ramanspy.datasets.bacteria(\"val\", folder=dir_)\nX_test, y_test = ramanspy.datasets.bacteria(\"test\", folder=dir_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shuffling the dataset we will use to train the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, y_train = shuffle(X_train.flat.spectral_data, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we construct the CNN model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class NN(tf.keras.Model):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n\n        self.nn = tf.keras.models.Sequential()\n        self.nn.add(tf.keras.Input(shape=(input_dim,)))\n        self.nn.add(tf.keras.layers.Dense(output_dim, activation='softmax'))\n\n    def call(self, x):\n        return self.nn(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialising the model instance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\nbatch_size = 32\nepochs = 15\ninput_dim = X_train.shape[-1]\noutput_dim = len(np.unique(y_train))\n\nopt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\nmodel = NN(input_dim, output_dim)\nmodel.compile(opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training the MLP model on the training dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the trained model on the unseen testing dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test.flat.spectral_data)\ny_pred = np.argmax(y_pred, axis=1)\n\nprint(f\"The accuracy of the NN model is: {accuracy_score(y_pred, y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confusion matrix:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cf_matrix = confusion_matrix(y_test, y_pred)\nsns.heatmap(cf_matrix, annot=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy profile:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loss profile:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}